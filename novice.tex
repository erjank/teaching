\chaplbl{Helping Novices Build Mental Models}{sec:novice}{20}{30}

The first task in teaching is to figure out who your learners are and
how best to help them.  Our approach is based on the
\href{https://en.wikipedia.org/wiki/Dreyfus\_model\_of\_skill\_acquisition}{Dreyfus
model of skill acquisition}, and more specifically on the work of
researchers like Patricia Benner, who studied how nurses progress from
being novices to being experts \cite{benner}.  Benner identified five
stages of cognitive development that most people go through in a
fairly consistent way\footnote{We say ``most'' and ``fairly'' because
human beings are variable, and there will always be outliers.
However, that shouldn't prevent us from making strong statements about
what's true for the majority.}. For our purposes, we simplify this to
three:

\begin{itemize}

\item
  A \emph{novice} is someone who doesn't know what they don't know,
  i.e., they don't yet know what the key ideas in the domain are or
  how they relate. They reason by analogy and guesswork, borrowing
  bits and pieces of their mental models of other domains which seem
  superficially similar. One sign that someone is a novice is that
  their questions aren't even wrong.

\item
  A \emph{competent practitioner} is someone who has a mental model
  that's good enough for everyday purposes: they can do normal tasks
  with normal effort under normal circumstances. This model does not
  have to be completely accurate in order to be useful: for example,
  the average driver's mental model of how a car works probably
  doesn't include most of the complexities that a mechanical engineer
  would be concerned with.

\item
  An \emph{expert} is someone who can easily handle situations that are
  out of the ordinary, diagnose the causes of problems, and so on. We
  will discuss expertise in more detail in \secref{sec:memory}.

\end{itemize}

One example of a mental model is the ball-and-spring model of
molecules that most of us encountered in high school chemistry. Atoms
aren't actually balls, and their bonds aren't actually springs, but
the model does a good job of helping people reason about chemical
compounds and their reactions.  Another model of an atom has a small
central ball (the nucleus) surrounded by orbiting electrons.  Again,
this model is wrong, but useful for many purposes.

Novices, competent practitioners, and experts need to be taught
differently.  In particular, presenting novices with a pile of facts
early on is counter-productive, because they don't yet have a model to
fit those facts into\footnote{In fact, presenting too many facts too
soon can actually reinforce the incorrect mental model they've cobbled
together \cite{}.}. Instead, the goal with novices is \emph{to help
them construct a working mental model} so that they have somewhere to
put facts.

As an example of what this means in practice, Software Carpentry's
\href{http://swcarpentry.github.io/shell-novice/}{lesson on the Unix
shell} introduces fifteen commands in three hours. Twelve minutes per
command may seem glacially slow, but the lesson's real purpose isn't
to teach those fifteen commands: it's to teach learners about paths,
history, tab completion, wildcards, pipes and filters, command-line
arguments, redirection, and all the other big ideas that the shell
depends on.  Once they understand those concepts, people can quickly
learn a repertoire of commands.  What's more, later lessons on how to
build functions in a programming language can refer back to pipes and
filters, which helps solidify both ideas.

\begin{callout}{Different Kinds of Lessons}{callout:different-kinds-of-lessons}

The cognitive differences between novices and competent practitioners
underpin the differences between two kinds of teaching materials. A
tutorial's purpose is to help newcomers to a field build a mental model;
a manual's role, on the other hand, is to help competent practitioners
fill in the gaps in their knowledge. Tutorials frustrate competent
practitioners because they move too slowly and say things that are
obvious (though of course they are anything but to newcomers). Equally,
manuals frustrate novices because they use jargon and \emph{don't}
explain things. One of the reasons Unix and C became popular is that
Kernighan et al's books \cite{fixme} somehow managed to be good tutorials
\emph{and} good manuals at the same time. Ray and Ray's book on Unix \cite{fixme}
and Fehily's introduction to SQL \cite{fixme} are among the very few
other books in computing that have accomplished this.

\end{callout}

One of the challenges in building a mental model is to clear away
things that \emph{don't} belong.  As Mark Twain said, ``It ain't what
you don't know that gets you into trouble. It's what you know for sure
that just ain't so.''

Broadly speaking, learners' misconceptions fall into three categories:

\begin{itemize}

\item
  Simple \emph{factual errors}, such as believing that Vancouver is
  the capital of British Columbia. These are simple to correct, but
  getting the facts right is not enough on its own.

\item
  \emph{Broken models}, such as believing that motion and acceleration
  must be in the same direction. We can address these by having them
  reason through examples to see contradictions.

\item
  \emph{Fundamental beliefs}, such as ``the world is only a few
  thousand years old'' or ``human beings cannot be affecting the
  planet's climate''. These usually cannot be addressed in class,
  since they are deeply connected to the learner's social identity and
  often cannot be reasoned away.

\end{itemize}

Teaching is most effective when instructors have a way to identify and
clear up learners' misconceptions \emph{while they are teaching}.  The
technical term for this is \emph{formative assessment}, which is
assessment that takes place during the lesson in order to form or
shape it.  Learners don't pass or fail formative assessments; instead,
its main purpose is to tell both the instructor and the learner how
the learner is doing, and what to focus on next.  For example, a music
teacher might ask a student to play a scale very slowly in order to
see whether she is breathing correctly, and if she is not, what she
should change.

The counterpoint to formative assessment is \emph{summative
assessment}, which is used at the end of the lesson to tell whether
the desired learning took place and whether the learner is ready to
move on.  Learners either pass or fail a summative assessment. One
example is a driving exam, which reassures the rest of society that
someone can safely be allowed on the road.

\begin{callout}{Connecting Formative and Summative Assessment}{callout:connecting-formative-summative}

One rule to use when designing lessons is that formative assessments
should prepare people for summative assessments: no one should ever
encounter a question on an exam for which the teaching did not prepare
them.

\end{callout}

In order to be useful during teaching, a formative assessment has to
be quick to administer and give an unambiguous result. The most widely
used kind of formative assessment is probably the multiple choice
question (MCQ). When designed well, these can do much more than just
tell whether someone knows something or not. For example, suppose we
are teaching children multi-digit addition. A well-designed MCQ would
be:

\begin{example}
\noindent
Q: what is 27 + 15 ?
\begin{enumerate}
\item 42
\item 32
\item 312
\item 33
\end{enumerate}
\end{example}

The correct answer is 42, but each of the other answers provides
valuable insight:

\begin{itemize}

\item
  If the child answers 32, she is throwing away the carry completely.

\item
  If she answers 312, she knows that she can't just discard the
  carried 1, but doesn't understand that it's actually a ten and needs
  to be added into the next column. In other words, she is treating
  each column of numbers as unconnected to its neighbors.

\item
  If she answers 33 then she knows she has to carry the 1, but is
  carrying it back into the same column it came from.

\end{itemize}

Each of these incorrect answers is a \emph{plausible distractor} with
\emph{diagnostic power}.   ``Plausible'' means that it looks like it
could be right: instructors will often put supposedly-silly answers
like ``a fish!'' on MCQs, but they don't provide any insight and
learners actually don't find them funny. ``Diagnostic power'' means
that each of the distractors helps the instructor figure out what to
explain to that particular learner next.

Instructors should use MCQs or some other kind of formative assessment
at least every 10-15 minutes in order to make sure that the class is
actually learning. Since the average attention span is usually only this
long, formative assessments also help break up instructional time and
re-focus attention. Formative assessments can also be used preemptively:
if you start a class with an MCQ and everyone can answer it correctly,
then you can safely skip the part of the lecture in which you were going
to explain something that your learners already know. (Doing this also
helps show learners that the instructor cares about how much they are
learning.)

\begin{callout}{When to Proceed?}{callout:novice-proceed}

As the instructor, what should you do if most of the class votes for
one of the wrong answers? What if the votes are evenly spread between
options?  The answer is, ``It depends.''  If the majority of the class
votes for a single wrong answer, you should go back and work on
correcting that particular misconception. If answers are pretty evenly
split between options, learners are probably guessing randomly and
it's a good idea to go back to a point where everyone was on the same
page.

If most of the class votes for the right answer, but a few vote for
wrong ones, you have to decide whether you should spend time getting
the minority caught up, or whether it's more important to keep the
majority engaged.  This is just one example of one of the most
important rules of teaching: no matter how hard you work, or what
teaching practices you use, you won't always be able to give everyone
the help they need.

\end{callout}

\begin{callout}{Peer Instruction}{callout:peer-instruction}

No matter how good a teacher is, she can only say one thing at a time.
How then can she clear up many different misconceptions in a reasonable
time?

The best solution developed so far is a technique called
\emph{\href{https://en.wikipedia.org/wiki/Peer\_instruction}{peer
instruction}}. Originally created by Eric Mazur at Harvard, it has
been studied extensively in a wide variety of contexts, including
programming \cite{fixme}. Peer instruction combines formative
assessment with student discussion and looks something like this:

\begin{enumerate}

\item
  Give a brief introduction to the topic.

\item
  Give students an MCQ that probes for misconceptions (rather than
  simple factual knowledge).

\item
  Have all the students vote on their answers to the MCQ.

  \begin{enumerate}

  \item
    If the students all have the right answer, move on.

  \item
    If they all have the same wrong answer, address that specific
    misconception.

  \item
    If they have a mix of right and wrong answers, give them several
    minutes to discuss those answers with one another in small groups
    (typically 2-4 students) and then reconvene and vote again.

  \end{enumerate}

\end{enumerate}

As \href{https://www.youtube.com/watch?t=1\&v=2LbuoxAy56o}{this video}
shows, group discussion significantly improves students' understanding
because it forces them to clarify their thinking, which can be enough to
call out gaps in reasoning. Re-polling the class then lets the
instructor know if they can move on, or if further explanation is
necessary. A final round of additional explanation and discussion after
the correct answer is presented gives students one more chance to
solidify their understanding.

Peer instruction is essentially a way to provide one-to-one mentorship
in a scalable way. Despite this, we usually do not use it in our
workshops because it takes people time to learn a new way to
learn---time that we don't have in our compressed two-day format.

\end{callout}

\begin{callout}{A Note on MCQ Design}{callout:a-note-on-mcq-design}

\begin{itemize}

\item
  A good MCQ tests for conceptual misunderstanding rather than simple
  factual knowledge. If you are having a hard time coming up with
  diagnostic distractors, then either you need to think more about your
  learners' mental models, or your question simply isn't a good starting
  point for an MCQ.

\item
  When you are trying to come up with distractors, think about questions
  that learners asked or problems they had the last time you taught this
  subject. If you haven't taught it before, think about your own
  misconceptions or ask colleagues about their experiences.

\end{itemize}

\end{callout}

\begin{callout}{Concept Inventories}{callout:concept-inventories}

The \href{https://en.wikipedia.org/wiki/Force\_Concept\_Inventory}{Force
Concept Inventory} is a set of MCQs designed to gauge understanding of
basic Newtonian mechanics. By interviewing a large number of
respondents, correlating their misconceptions with patterns of right and
wrong answers to questions, and then improving the questions, it's
possible to construct a very precise diagnostic tool. However, it's very
costly to do this, and students' ability to search for answers on the
internet is an ever-increasing threat to its validity.

\end{callout}

Designing an MCQ with plausible distractors is useful even if it is
never used in class because it forces the instructor to think about
the learners' mental models and how they might be broken---in short,
to put themselves into the learners' heads and see the topic from
their point of view.

\begin{callout}{Why We Don't Assess During Registration}{callout:why-we-dont-assess-during-registration}

Unfortunately, most formal educational systems train people to treat all
assessment as summative, i.e., to think of every interaction with a
teacher as an evaluation, rather than as a chance to shape instruction.
For example, we use a short pre-assessment questionnaire to profile
learners before workshops to help instructors tune the pace and level of
material. We send this questionnaire out after people have registered
rather than making it part of the sign-up process because when we did
the latter, many people concluded that since they couldn't answer all
the questions, they shouldn't enrol. We were therefore scaring off many
of the people we most wanted to help.

\end{callout}

\seclbl{Teaching Practices}{sec:novice-practices}

\subseclbl{Status Flag}{sec:status-flags}

\fixme{Status Flags}

\subseclbl{Minute Cards}{sec:minute-cards}

We frequently use sticky notes as \emph{minute cards}: before each
break, learners take a minute to write one positive thing on the green
sticky note (e.g., one thing they've learned that they think will be
useful), and one thing they found too fast, too slow, confusing, or
irrelevant on the red one. They can use the red sticky note for
questions that haven't yet been answered. While they are enjoying
their coffee or lunch, the instructors review and cluster these to
find patterns. It only takes a few minutes to see what learners are
enjoying, what they still find confusing, what problems they're
having, and what questions are still unanswered.

\seclbl{Challenges}{sec:novice-challenges}

\begin{challenge}{Your Mental Models}{chal:novice-your-models}

What do you do for a living? What is one mental model you use to frame
and understand your work?

\end{challenge}

\begin{challenge}{Symptoms of Being a Novice}{chal:novice-symptoms}

What are the symptoms of being a novice?  I.e., what does someone do
or say that leads you to classify them as a novice in some domain?

\end{challenge}

\begin{challenge}{Modelling Novice Mental Models}{chal:novice-models}

Create a multiple choice question related to a topic you intend to teach
and explain the diagnostic power of each its distractors (i.e., what
misconception each distractor is meant to identify).

When you are done, give your MCQ to a partner, and have a look at
theirs.  Is the question ambiguous?  Are the misconceptions plausible?
Do the distractors actually test for them?  Are any likely
misconceptions \emph{not} tested for?

\end{challenge}

\begin{challenge}{Other Kinds of Formative Assessment}{chal:novice-other-formative}

Describe another kind of formative assessment you have seen or used and
explain how it helps both the instructor and the learner figure out
where they are and what they need to do next.

\end{challenge}

\begin{challenge}{Icebergs}{chal:novice-iceberg}

An example of how solving problems can help people correct broken
mental models, consider this problem from \cite{epstein}. Imagine that
you have placed a cake of ice in a bathtub and then filled the tub to
the rim with water. When the ice melts, does the water level go up (so
that the tub overflows), go down, or stay the same?

\fixme{FIGURE}

The correct answer is that it stays the same; figuring out why helps
people build a model of the relationship between weight, volume, and
density.

\end{challenge}

\begin{challenge}{chal:minute-cards}

Write one thing you learned this morning that you found useful on your
green sticky note, and one question you have about the material on the
red. Do \emph{not} put your name on the notes: this is meant to be
anonymous feedback. Add your notes to the pile by the door as you leave
to get coffee.

\end{challenge}
